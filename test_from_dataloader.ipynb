{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, warnings\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.metrics import f1_score\n",
    "import multiprocessing as mp\n",
    "\n",
    "from utils.Dataset import CustomAugmentation, CustomDataset\n",
    "from utils.models import ResNet50, UnetResnet50\n",
    "from utils.utils import dense_crf_wrapper\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "label_to_str = ['1', '1+', '1++', '3', '2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading start\n",
      "model loading end\n"
     ]
    }
   ],
   "source": [
    "# classification model\n",
    "print('model loading start')\n",
    "\n",
    "model_classification = ResNet50()\n",
    "model_classification.load_state_dict(torch.load('./saved/best2.pt'))\n",
    "model_classification = model_classification.model.to(device)\n",
    "\n",
    "# segmentation classification\n",
    "model_segmentation = UnetResnet50()\n",
    "model_segmentation.load_state_dict(torch.load('./saved/seg1.pt').state_dict())\n",
    "model_segmentation = model_segmentation.model.to(device)\n",
    "\n",
    "model_seg_classification = ResNet50()\n",
    "model_seg_classification.load_state_dict(torch.load('./saved/seg_class1.pt'))\n",
    "model_seg_classification = model_seg_classification.model.to(device)\n",
    "\n",
    "softmax = torch.nn.Softmax()\n",
    "normalize = torchvision.transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "\n",
    "\n",
    "model_classification.eval()\n",
    "model_segmentation.eval()\n",
    "model_seg_classification.eval()\n",
    "\n",
    "print('model loading end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam_resnet50(model, tensor_img, label, device):\n",
    "    # grad cam\n",
    "    target_layers = [model.layer4[-1]]\n",
    "    input_tensor = tensor_img\n",
    "    cam = GradCAMPlusPlus(model=model, target_layers=target_layers, use_cuda=device)\n",
    "    target_category = np.array(label.detach().cpu())\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)\n",
    "    return grayscale_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label_pred(img, label, pred):\n",
    "    font = ImageFont.truetype('arial.ttf', 40)\n",
    "    img = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    text = f'label: {label_to_str[label]}\\npred:{label_to_str[pred]}'\n",
    "    draw.text((10,10), text, font=font)\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "val_transform = CustomAugmentation('val')\n",
    "val_dataset = CustomDataset(data_path='../data/QCdataset', mode='val', transform=val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4,\n",
    "                                        drop_last=False,\n",
    "                                        pin_memory=(torch.cuda.is_available()),\n",
    "                                        collate_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "val_transform = CustomAugmentation('val')\n",
    "val_dataset = CustomDataset(data_path='../data/QCdataset', mode='test', transform=val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4,\n",
    "                                        drop_last=False,\n",
    "                                        pin_memory=(torch.cuda.is_available()),\n",
    "                                        collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15/15 - class: 21.666666666666668, seg_class: 23.333333333333332, crf_class: 25.0, : 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference end\n",
      "save vis\n"
     ]
    }
   ],
   "source": [
    "print('inference start')\n",
    "\n",
    "pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "count = [0, 0, 0, 0]\n",
    "total = 0\n",
    "num_img = len(val_loader)\n",
    "fig_idx = 0\n",
    "\n",
    "# img\n",
    "img_size = 224\n",
    "num_img = len(val_loader)\n",
    "# num_img = 64\n",
    "vis_img = np.zeros((batch_size*num_img*img_size, 9*img_size, 3),np.uint8)\n",
    "\n",
    "# fig, ax = plt.subplots(num_img, 4)\n",
    "for batch, (image, label, mask) in pbar:\n",
    "    image, label, mask = image.to(device), label.to(device), mask.to(device)\n",
    "\n",
    "    # classification\n",
    "    output_classification = model_classification(image)\n",
    "    pred_classification = output_classification.argmax(1)\n",
    "    count[0] += (pred_classification == label).sum().item()\n",
    "\n",
    "    # segmentation\n",
    "    output_segmentation = model_segmentation(image)\n",
    "\n",
    "    # threshold\n",
    "    output_segmentation_th = torch.where(output_segmentation>0., 1., 0.)\n",
    "\n",
    "    # crf\n",
    "    image_unnorm = 255*torch.div(torch.add(image, -image.min()),torch.add(image.max(), -image.min()))\n",
    "    probs_seg = torch.nn.functional.softmax(output_segmentation, dim=1).detach().cpu().numpy()\n",
    "\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    images_rgb = image_unnorm.detach().cpu().numpy().astype(np.uint8).transpose(0, 2, 3, 1)\n",
    "    probs_crf = np.array(pool.map(dense_crf_wrapper, zip(images_rgb, probs_seg)))\n",
    "    pool.close()\n",
    "    probs_crf = torch.tensor(probs_crf).to(device)\n",
    "\n",
    "    # masked image\n",
    "    masked_seg_images = torch.mul(image_unnorm, torch.stack([output_segmentation_th[:,1]]*3, dim=1)).detach().cpu()\n",
    "    masked_crf_images = torch.mul(image_unnorm, torch.stack([probs_crf[:,1,:,:]]*3, dim=1)).detach().cpu()\n",
    "    masked_gt_images = torch.mul(image_unnorm, torch.stack([mask.squeeze()]*3, dim=1)).detach().cpu()\n",
    "\n",
    "\n",
    "    # masked image transform\n",
    "    result = []\n",
    "    for masked_seg_image in masked_seg_images:\n",
    "        result.append(normalize(masked_seg_image))\n",
    "    input_seg_classification = torch.stack(result,dim=0).to(device)\n",
    "    result = []\n",
    "    for masked_crf_image in masked_crf_images:\n",
    "        result.append(normalize(masked_crf_image))\n",
    "    input_crf_classification = torch.stack(result,dim=0).to(device)\n",
    "    result = []\n",
    "    for masked_gt_image in masked_gt_images:\n",
    "        result.append(normalize(masked_gt_image))\n",
    "    input_gt_classification = torch.stack(result,dim=0).to(device)\n",
    "\n",
    "    # seg masked image classification\n",
    "    output_seg_classification = model_seg_classification(input_seg_classification)\n",
    "    pred_seg_classification = output_seg_classification.argmax(1)\n",
    "    count[1] += (pred_seg_classification == label).sum().item()\n",
    "    # crf masked image classification\n",
    "    output_crf_classification = model_seg_classification(input_crf_classification)\n",
    "    pred_crf_classification = output_crf_classification.argmax(1)\n",
    "    count[2] += (pred_crf_classification == label).sum().item()\n",
    "    # gt masked image classification\n",
    "    output_gt_classification = model_seg_classification(input_gt_classification)\n",
    "    pred_gt_classification = output_gt_classification.argmax(1)\n",
    "    count[3] += (pred_gt_classification == label).sum().item()\n",
    "    total += batch_size\n",
    "\n",
    "    # print info\n",
    "    pbar.update()\n",
    "    pbar.set_description(\n",
    "                    f'{batch+1}/{len(val_loader)} - '\n",
    "                    f'class: {100*count[0]/total}, '\n",
    "                    f'seg_class: {100*count[1]/total}, '\n",
    "                    f'crf_class: {100*count[2]/total}, '\n",
    "                )\n",
    "\n",
    "    # grad_cam\n",
    "    grad_cam_class = grad_cam_resnet50(model_classification, image, label, device)\n",
    "    grad_cam_seg = grad_cam_resnet50(model_seg_classification, input_seg_classification, label, device)\n",
    "    grad_cam_crf = grad_cam_resnet50(model_seg_classification, input_crf_classification, label, device)\n",
    "\n",
    "    # img save\n",
    "    raws = image_unnorm.detach().cpu().numpy().astype(np.uint8).transpose(0, 2, 3, 1)\n",
    "    probs = 255*np.stack([probs_seg[:,1]]*3, axis=1).transpose(0, 2, 3, 1)\n",
    "    ths = 255*torch.stack([output_segmentation_th[:,1]]*3, dim=1).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    crfs = 255*torch.stack([probs_crf[:,1,:,:]]*3, dim=1).detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    masked_segs = masked_seg_images.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    masked_crfs = masked_crf_images.detach().cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    for idx in range(raws.shape[0]):\n",
    "        # grad cam vis\n",
    "        visualization_class = show_cam_on_image(raws[idx]/255, grad_cam_class[idx, :], use_rgb=True)\n",
    "        visualization_seg = show_cam_on_image(raws[idx]/255, grad_cam_seg[idx, :], use_rgb=True)\n",
    "        visualization_crf = show_cam_on_image(raws[idx]/255, grad_cam_crf[idx, :], use_rgb=True)\n",
    "\n",
    "        # draw label img\n",
    "        visualization_class = draw_label_pred(visualization_class, label[idx].detach().cpu().numpy(), pred_classification[idx].detach().cpu().numpy())\n",
    "        visualization_seg = draw_label_pred(visualization_seg, label[idx].detach().cpu().numpy(), pred_seg_classification[idx].detach().cpu().numpy())\n",
    "        visualization_crf = draw_label_pred(visualization_crf, label[idx].detach().cpu().numpy(), pred_crf_classification[idx].detach().cpu().numpy())\n",
    "\n",
    "        row = np.concatenate((raws[idx], probs[idx], ths[idx], crfs[idx], masked_segs[idx], masked_crfs[idx], visualization_class, visualization_seg, visualization_crf), axis=1)\n",
    "        if fig_idx<64:\n",
    "            vis_img[fig_idx*img_size:(fig_idx+1)*img_size,:,:] = row\n",
    "        fig_idx += 1\n",
    "\n",
    "pbar.close()\n",
    "print('inference end')\n",
    "im = Image.fromarray((vis_img).astype(np.uint8))\n",
    "im.save(\"test_visualization.jpg\")\n",
    "print('save vis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lightweight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
